# å½“å‰è„šæœ¬æ¥è‡ªäºhttp://script.345yun.cnè„šæœ¬åº“ä¸‹è½½ï¼
#
#
# é˜…è¯»å…¥å£ï¼šhttps://file.52bin.cn/img/ID9/202509/68c63a96f101e.jpeg å¾®ä¿¡æ‰«ç æ‰“å¼€
# é…ç½®è¯´æ˜ï¼š
# 1. ç¯å¢ƒå˜é‡ mmyd_ck: é…ç½®cookieè´¦å·ä¿¡æ¯bbuså€¼ï¼Œæ”¯æŒå¤šè´¦å·åˆ†éš”ç¬¦ï¼šæ¢è¡Œç¬¦ã€@ã€& ä¾‹å¦‚eyxxxxxxxxx ä¸è¦å‰é¢çš„bbus=
# 2. ç¯å¢ƒå˜é‡ mmyd_ua: é…ç½®UAä¿¡æ¯      https://useragent.todaynav.com/ å¾®ä¿¡æ‰“å¼€æ­¤ç½‘ç«™å³å¯ è¯·ä½¿ç”¨ä½ çš„å¾®ä¿¡çš„User-Agent
# 3. ç¯å¢ƒå˜é‡ mmyd_url: æ£€æµ‹æ–‡ç« æäº¤æ¥å£çš„URLï¼ˆå¯é€‰ï¼Œå¦‚http://192.168.124.201:9900/check_readï¼‰è¯·ä½¿ç”¨è‡ªå·±çš„è¿™ä¸ªåªæ˜¯ä¾‹å­
# 4. ç¯å¢ƒå˜é‡ mmyd_token: PushPlusæ¨é€åŠ tokenï¼ˆå¯é€‰ï¼‰
# 5. ç¯å¢ƒå˜é‡ mmyd_tx: PushPlusæ¨é€åŠ tokenï¼ˆå¯é€‰ï¼‰
# ä½¿ç”¨è¯´æ˜ï¼š
# - é¦–è´¦å·é‡‡ç”¨å›ºå®šé‚€è¯·ç ï¼Œè¯·wxç‚¹å‡»é˜…è¯»å…¥å£ã€‚
# - æ”¯æŒå¤šè´¦å·æ‰¹é‡è¿è¡Œï¼Œè‡ªåŠ¨åˆ·æ–°Cookie
# - è‡ªåŠ¨æ£€æµ‹æ–‡ç« å¹¶æ¨é€é€šçŸ¥ï¼ˆéœ€é…ç½®mmyd_tokenï¼‰
# - è‡ªåŠ¨æç°åŠŸèƒ½ï¼Œæ»¡è¶³5000é‡‘å¸è‡ªåŠ¨æç°
# - å¦‚æœé…ç½®äº†mmyd_urlï¼Œä¼šå…ˆå°è¯•è‡ªåŠ¨è¿‡æ£€ï¼Œå¤±è´¥åˆ™æ¨é€é€šçŸ¥
#
# æœ¬è„šæœ¬ä»…ä¾›å­¦ä¹ äº¤æµï¼Œè¯·åœ¨ä¸‹è½½åçš„24å°æ—¶å†…å®Œå…¨åˆ é™¤
# è¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”æˆ–éæ³•ç›®çš„ï¼Œå¦åˆ™åæœè‡ªè´Ÿ

# å›ºå®šæ³¨é‡Šå†…å®¹
fixed_comments = """# çŒ«çŒ«é˜…è¯»è„šæœ¬ 4.0
#
# é˜…è¯»å…¥å£ï¼šhttps://file.52bin.cn/img/ID9/202509/68c63a96f101e.jpeg å¾®ä¿¡æ‰«ç æ‰“å¼€
# 
# é…ç½®è¯´æ˜ï¼š
# 1. ç¯å¢ƒå˜é‡ mmyd_ck: é…ç½®cookieè´¦å·ä¿¡æ¯bbuså€¼ï¼Œæ”¯æŒå¤šè´¦å·åˆ†éš”ç¬¦ï¼šæ¢è¡Œç¬¦ã€@ã€&
# 2. ç¯å¢ƒå˜é‡ mmyd_ua: é…ç½®UAä¿¡æ¯      https://useragent.todaynav.com/ å¾®ä¿¡æ‰“å¼€æ­¤ç½‘ç«™å³å¯ è¯·ä½¿ç”¨ä½ çš„å¾®ä¿¡çš„User-Agent
# 3. ç¯å¢ƒå˜é‡ mmyd_url: æ£€æµ‹æ–‡ç« æäº¤æ¥å£çš„URLï¼ˆå¯é€‰ï¼Œå¦‚http://192.168.124.201:9900/check_readï¼‰
# 4. ç¯å¢ƒå˜é‡ mmyd_token: PushPlusæ¨é€åŠ tokenï¼ˆå¯é€‰ï¼‰
#
# ä½¿ç”¨è¯´æ˜ï¼š
# - é¦–è´¦å·é‡‡ç”¨å›ºå®šé‚€è¯·ç ï¼Œè¯·wxç‚¹å‡»é˜…è¯»å…¥å£ã€‚
# - æ”¯æŒå¤šè´¦å·æ‰¹é‡è¿è¡Œï¼Œè‡ªåŠ¨åˆ·æ–°Cookie
# - è‡ªåŠ¨æ£€æµ‹æ–‡ç« å¹¶æ¨é€é€šçŸ¥ï¼ˆéœ€é…ç½®mmyd_tokenï¼‰
# - è‡ªåŠ¨æç°åŠŸèƒ½ï¼Œæ»¡è¶³5000é‡‘å¸è‡ªåŠ¨æç°
# - å¦‚æœé…ç½®äº†mmyd_urlï¼Œä¼šå…ˆå°è¯•è‡ªåŠ¨è¿‡æ£€ï¼Œå¤±è´¥åˆ™æ¨é€é€šçŸ¥
#
# æœ¬è„šæœ¬ä»…ä¾›å­¦ä¹ äº¤æµï¼Œè¯·åœ¨ä¸‹è½½åçš„24å°æ—¶å†…å®Œå…¨åˆ é™¤
# è¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”æˆ–éæ³•ç›®çš„ï¼Œå¦åˆ™åæœè‡ªè´Ÿ"""



import requests
import json
import os
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import re
import time
import random
from requests.exceptions import RequestException


# åˆ›å»ºå…¨å±€ session
session = requests.Session()

# APIè®¤è¯ç›¸å…³
API_URL = os.getenv("mmyd_url")  # æ£€æµ‹æ–‡ç« æäº¤æ¥å£URL
PUSH_TOKEN = os.getenv("mmyd_token")  # PushPlusæ¨é€token
UA_USER_AGENT = os.getenv("mmyd_ua")  # UA
PROXY_URL = os.getenv("mmyd_proxy")  #ä»£ç†

# æ–°å¢: PushPlusé€šçŸ¥å‡½æ•°
def send_pushplus_notification(token, title, content):
    """ä½¿ç”¨PushPluså‘é€é€šçŸ¥"""
    try:
        url_pushplus = "http://www.pushplus.plus/send"
        data_pushplus = {
            "token": token,
            "title": title,
            "content": content,
            "template": "html"
        }
        response = requests.post(url_pushplus, data=data_pushplus, timeout=10)
        response.raise_for_status()
        result = response.json()
        if result.get("code") == 200:
            print(f"âœ… PushPlusé€šçŸ¥å‘é€æˆåŠŸ", flush=True)
        else:
            print(f"â— PushPlusé€šçŸ¥å‘é€å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}", flush=True)
    except Exception as e:
        print(f"â— PushPlusé€šçŸ¥è¯·æ±‚å¼‚å¸¸: {str(e)}", flush=True)


def fetch_luodi_url():
    url = "http://thr.zuoanai.cn/baobaocode.php"
    headers = {
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
        "Connection": "keep-alive",
        "Host": "thr.zuoanai.cn",
        "Referer": "http://thr.zuoanai.cn/",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0",
        "X-Requested-With": "XMLHttpRequest"
    }
    resp = session.get(url, headers=headers, timeout=15, proxies=proxies)
    resp.raise_for_status()
    data = resp.json()
    luodi_url = data.get("data", {}).get("luodi")
    print(f"è·å–åˆ°æ´»åŠ¨åœ°å€: {luodi_url}")
    return luodi_url


def get_first_redirect(luodi_url):
    parsed = urlparse(luodi_url)
    host = parsed.hostname
    path = parsed.path + (f"?{parsed.query}" if parsed.query else "")
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/tpg,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "X-Requested-With": "com.tencent.mm",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    url = f"http://{host}{path}"
    resp = session.get(url, headers=headers, allow_redirects=False, timeout=15)
    if resp.status_code == 302:
        location = resp.headers.get('Location')
        # print(f"302è·³è½¬åœ°å€: {location}")
        parsed2 = urlparse(location)
        new_host = parsed2.hostname
        m = re.search(r'/haobaobao/([^/?]+)', parsed2.path)
        cid = m.group(1) if m else None
        # print(f"æ–°åŸŸå: {new_host}, cid: {cid}")
        return new_host, cid
    else:
        print(f"æœªè¿”å›302ï¼ŒçŠ¶æ€ç : {resp.status_code}")
        print(resp.text)
        return None, None


def get_redirect_url(code, cid):
    url = f"http://soicq.hzyunyan.cn/blank_ground.html?type=bao&cid={cid}&code={code}&state=1"
    headers = {
        "Host": "soicq.hzyunyan.cn",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9",
        "X-Requested-With": "com.tencent.mm",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    resp = session.get(url, headers=headers, allow_redirects=False, timeout=15)
    if resp.status_code == 302:
        location = resp.headers.get('Location')
        # print(f"redirectæ¥å£302 Location: {location}")
        return location
    else:
        print(f"redirectæ¥å£æœªè¿”å›302ï¼ŒçŠ¶æ€ç : {resp.status_code}")
        print(resp.text)
        return None


def get_bbus_from_url(bbus_url):
    # å¤„ç†qå‚æ•°ï¼Œå»æ‰vå‰ç¼€
    parsed = urlparse(bbus_url)
    qs = parse_qs(parsed.query)
    # å¤„ç†qå‚æ•°
    if 'q' in qs and qs['q']:
        qval = qs['q'][0]
        if qval.startswith('v') and len(qval) > 1:
            qs['q'][0] = qval[1:]
    # å¤„ç†vå‚æ•°ï¼Œæ›¿æ¢ä¸ºå½“å‰æ—¶é—´æˆ³å‡6å°æ—¶2ç§’
    if 'v' in qs and qs['v']:
        now = int(time.time())
        v_new = now - (6 * 3600)
        qs['v'][0] = str(v_new)
    new_query = urlencode(qs, doseq=True)
    bbus_url = urlunparse(parsed._replace(query=new_query))
    headers = {
        "Host": parsed.hostname,
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Connection": "keep-alive"
    }
    resp = session.get(bbus_url, headers=headers, timeout=15)
    # print(resp.text)
    print(f"è¯·æ±‚: {bbus_url}")
    print("--- å“åº”æ ‡å¤´ ---")
    for k, v in resp.headers.items():
        print(f"{k}: {v}")
    set_cookie = resp.headers.get('Set-Cookie', '')
    m = re.search(r'bbus=([^;]+)', set_cookie)
    bbus = m.group(1) if m else None
    print(f"bbus: {bbus}")
    return bbus


def get_location_domain(cid, bbus, new_host):
    """
    1. GET /haobaobao/v{cid}?v=xxxï¼Œå¸¦ bbus cookieï¼Œè·å– 302 Location åŸŸå
    è¿”å› (location_url, location_domain)
    """
    v = int(time.time())
    url = f"http://{new_host}/haobaobao/v{cid}?v={v}"
    headers = {
        "Host": new_host,
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/tpg,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "X-Requested-With": "com.tencent.mm",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}"
    }
    resp = session.get(url, headers=headers, allow_redirects=False, timeout=15)
    location = resp.headers.get('Location')
    if not location:
        print(f"æœªè·å–åˆ°Locationï¼ŒçŠ¶æ€ç : {resp.status_code}")
        return None, None
    # æå–åŸŸå
    parsed = urlparse(location)
    location_domain = parsed.hostname
    # print(f"Location: {location}\nLocationåŸŸå: {location_domain}")
    return location, location_domain


def post_mwtmpdomain(location_domain, bbus):
    """
    2. POST /mwtmpdomainï¼Œå¸¦ bbus cookieï¼Œè¿”å› domain/sk
    """
    url = f"http://{location_domain}/mwtmpdomain"
    headers = {
        "Host": location_domain,
        "Connection": "keep-alive",
        "Content-Length": "0",
        "User-Agent": UA_USER_AGENT,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "X-Requested-With": "XMLHttpRequest",
        "Origin": f"http://{location_domain}",
        "Referer": f"http://{location_domain}/haobaobao/home?v=1700447805",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}"
    }
    resp = session.post(url, headers=headers, timeout=15)
    try:
        data = resp.json()
        domain_url = data['data']['domain']
        from urllib.parse import urlparse, parse_qs
        parsed = urlparse(domain_url)
        qs = parse_qs(parsed.query)
        sk = qs.get('sk', [None])[0]
        # print(f"domain: {domain_url}\nsk: {sk}")
        return domain_url, sk
    except Exception as e:
        print(f"è§£ædomain/skå¤±è´¥: {e}")
        return None, None


def get_user_url(cid, bbus, new_host):
    """
    ç»¼åˆæµç¨‹ï¼š
    1. é€šè¿‡ get_location_domain è·å– Location åŸŸå
    2. é€šè¿‡ post_mwtmpdomain è·å– domain/sk
    è¿”å› domain_url, sk
    """
    location_url, location_domain = get_location_domain(cid, bbus, new_host)
    if not location_domain:
        return None, None
    domain_url, sk = post_mwtmpdomain(location_domain, bbus)
    return domain_url, sk


def get_article_link(host, sk):
    """
    è·å–æ–‡ç« link
    """
    now_ms = int(time.time() * 1000)
    mysign = random.randint(100, 999)
    vs = random.randint(100, 200)
    rmemakdk_url = f"http://{host}/smkrdeas?time={now_ms}&mysign={mysign}&vs={vs}&sk={sk}"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "User-Agent": UA_USER_AGENT,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "X-Requested-With": "XMLHttpRequest",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    # print(f"\nğŸ“– è¯·æ±‚æ–‡ç« ä»»åŠ¡: {rmemakdk_url}")
    resp = session.get(rmemakdk_url, headers=headers, timeout=15)
    return resp.json()


def visit_article_link(link):
    """
    è®¿é—®æ–‡ç« linkï¼Œæ¨¡æ‹Ÿé˜…è¯»
    """
    article_headers = {
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Connection": "keep-alive"
    }
    print(f"ğŸ“– å¼€å§‹æ¨¡æ‹Ÿé˜…è¯»æ–‡ç« ...")
    resp = session.get(link, headers=article_headers, timeout=15)
    return resp


def submit_read_result(host, sk, sleep_time):
    """
    æäº¤é˜…è¯»å®Œæˆ
    """
    psign = random.randint(200, 400)
    jiajinbimao_url = f"http://{host}/jiajinbimao?time={sleep_time}&psign={psign}&sk={sk}"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "User-Agent": UA_USER_AGENT,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "X-Requested-With": "XMLHttpRequest",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    # print(f"ğŸ“– æäº¤é˜…è¯»å®Œæˆ")
    resp2 = session.get(jiajinbimao_url, headers=headers, timeout=15)
    return resp2.json()


def read_article(domain_url, sk):
    """
    1. GET /rmemakdk è·å–æ–‡ç« link
    2. è¯·æ±‚linkï¼Œç­‰å¾…20-30ç§’
    3. GET /jiajinbimao è·å–é˜…è¯»ç»“æœ
    æ£€æµ‹æ–‡ç« bizç‰¹æ®Šå¤„ç†ï¼šå¦‚bizåœ¨æ£€æµ‹åˆ—è¡¨ï¼Œç­‰å¾…120-130ç§’ï¼Œæç¤ºæ‰‹åŠ¨é˜…è¯»
    """
    check_biz_list = [
        "MzkzMTYyMDU0OQ==", "Mzk0NDcxMTk2MQ==",
        "MzkzNTYxOTgyMA==", "MzkzNDYxODY5OA==",
        "MzkwNzYwNDYyMQ==", "MzkyNjY0MTExOA==",
        "MzkwMTYwNzcwMw==", "Mzg4NTcwODE1NA==",
        "MzkyMjYxNzQ2NA==", "Mzk4ODQzNjU1OQ==",
        "MzkyMTc0MDU5Nw==", "Mzk4ODQzNzU3NA==",
        "Mzk5MDc1MDQzOQ==",
    ]
    parsed = urlparse(domain_url)
    host = parsed.hostname
    # 1. è·å–æ–‡ç« link
    try:
        data = get_article_link(host, sk)
        link = data.get('data', {}).get('link')
        if not link:
            if data.get('errcode') == 407:
                print('âš ï¸ 60åˆ†é’Ÿåå¯ç»§ç»­é˜…è¯»ï¼')
            elif data.get('errcode') == 405:
                print(f"âŒ {data.get('msg')}")
            else:
                print(f"âŒ æœªè·å–åˆ°æ–‡ç« link: {data}")
            return False
        # print(f"âœ… è·å–åˆ°æ–‡ç« : {link}")
        # æå–biz
        biz_match = parse_qs(urlparse(link).query).get('__biz', [None])[0]
        print(f"æ–‡ç« æ ‡é¢˜: {biz_match}")
        print(f"ğŸ“– å¼€å§‹é˜…è¯»: {link}", flush=True)
        # æ£€æµ‹æ–‡ç« ç‰¹æ®Šå¤„ç†
        auto_checked = False
        if biz_match in check_biz_list or biz_match is None:
            wait_time = random.randint(120, 130)
            title = "âš ï¸ çŒ«çŒ«æ£€æµ‹æ–‡ç« ï¼è¯·åœ¨120så†…å®Œæˆé˜…è¯»ï¼"
            content = f"""
            âš ï¸ è¯·åœ¨120så†…å®Œæˆé˜…è¯»ï¼
            âš ï¸ æ¯æ¬¡é˜…è¯»ä¸å¾—å°‘äº8ç§’ï¼
            æ–‡ç« é“¾æ¥ï¼š{link}
            å½“å‰æ—¶é—´ {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}
            """
            # è‡ªåŠ¨è¿‡æ£€é€»è¾‘
            auto_checked = False
            if API_URL:
                print(f"é€å…¥è‡ªåŠ¨è¿‡æ£€...")
                payload = {"url": link,"ck":bbus,"ua":UA_USER_AGENT,'version':'3.0'}
                try:
                    resp = requests.post(API_URL, json=payload, timeout=60).json()
                    if resp['status'] == 'success':
                        time.sleep(25)
                        print(f"âœ… è‡ªåŠ¨è¿‡æ£€æˆåŠŸï¼Œè·³è¿‡æ¨é€")
                        auto_checked = True
                    else:
                        print(f"âŒ è‡ªåŠ¨è¿‡æ£€å¤±è´¥", resp['message'])
                except Exception as e:
                    print(f"è‡ªåŠ¨è¿‡æ£€è¯·æ±‚å¼‚å¸¸: {e}")

            if not auto_checked:
                if PUSH_TOKEN:
                    print("å¼€å§‹æ¨é€æ–‡ç« ...")
                    send_pushplus_notification(PUSH_TOKEN, title, content)
                else:
                    print("æœªé…ç½®æ¨é€tokenï¼Œå°è¯•ä½¿ç”¨é’é¾™é…ç½®æ–‡ä»¶æ¨é€")
                    print(QLAPI.notify(title, content))
                print(f"â³ æ£€æµ‹æ–‡ç« ç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
            # æ£€æµ‹æ–‡ç« ä¸è¯·æ±‚linkï¼Œä½†éœ€è¦è°ƒç”¨jiajinbimaoæ¥å£
            sleep_time = random.randint(9, 18)
        else:
            # 2. è¯·æ±‚ linkï¼Œç­‰å¾…20-30ç§’
            try:
                print(link)
                visit_article_link(link)
                sleep_time = random.randint(9, 18)
                print(f"â³ ç­‰å¾… {sleep_time} ç§’æ¨¡æ‹Ÿé˜…è¯»...")
                time.sleep(sleep_time)
            except Exception as e:
                print(f"âŒ é˜…è¯»æ–‡ç« è¯·æ±‚å¤±è´¥: {e}")
                return False
        # 3. GET /jiajinbimao è·å–é˜…è¯»ç»“æœ
        max_retries = 3
        for retry_count in range(max_retries):
            try:
                data2 = submit_read_result(host, sk, sleep_time)
                if data2.get('errcode') == 0:
                    d = data2.get('data', {})
                    print(
                        f"âœ… é˜…è¯»å®Œæˆï¼æœ¬æ¬¡é‡‘å¸: {d.get('gold')}ï¼Œä»Šæ—¥å·²è¯»: {d.get('day_read')}ï¼Œä»Šæ—¥é‡‘å¸: {d.get('day_gold')}ï¼Œå½“å‰é‡‘å¸: {d.get('last_gold')}ï¼Œå‰©ä½™å¯è¯»: {d.get('remain_read')}")
                    return True
                elif data2.get('errcode') == 405 and 'æœªèƒ½è·å–åˆ°ç”¨æˆ·ä¿¡æ¯' in str(data2.get('msg')):
                    print(f"âš ï¸ ç¬¬ {retry_count + 1}/{max_retries} æ¬¡è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {data2.get('msg')}ï¼Œæ­£åœ¨é‡è¯•...")
                    if retry_count == max_retries - 1:
                        print(f"âŒ è¿ç»­ {max_retries} æ¬¡ç”¨æˆ·ä¿¡æ¯è·å–å¤±è´¥ï¼Œé€€å‡ºè¿è¡Œ")
                        return False
                    time.sleep(2)
                    continue
                else:
                    print(f"âŒ é˜…è¯»å®Œæˆæ¥å£è¿”å›å¤±è´¥: {data2}")
                    return False
            except requests.exceptions.ReadTimeout:
                print(f"â° ç¬¬ {retry_count + 1}/{max_retries} æ¬¡è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•...")
                if retry_count == max_retries - 1:
                    print(f"âŒ è¿ç»­ {max_retries} æ¬¡è¯·æ±‚è¶…æ—¶ï¼Œé€€å‡ºè¿è¡Œ")
                    return False
                time.sleep(2)
            except Exception as e:
                print(f"âŒ é˜…è¯»å®Œæˆæ¥å£è¯·æ±‚å¤±è´¥: {e}")
                return False
    except Exception as e:
        print(f"âŒ è§£ææ–‡ç« ä»»åŠ¡å“åº”å¤±è´¥: {e}")
        return False


def confirm_withdraw(domain_url, bbus, signid):
    """
    ç¡®è®¤æç°
    """
    from urllib.parse import urlparse
    host = urlparse(domain_url).hostname
    url = f"http://{host}/haobaobao/getwithdraw"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "User-Agent": UA_USER_AGENT,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": f"http://{host}",
        "Referer": f"http://{host}/haobaobao/withdraw",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}",
        "X-Requested-With": "XMLHttpRequest"
    }
    data = f"signid={signid}&ua=2&ptype=0&paccount=&pname="
    # print(f"\nğŸ”„ æ­£åœ¨ç¡®è®¤æç°")
    resp = session.post(url, headers=headers, data=data, timeout=15)
    try:
        res_json = resp.json()
        if res_json.get('errcode') == 0:
            print("âœ… ç¡®è®¤æç°æˆåŠŸ")
        else:
            if res_json.get('errcode') == 405:
                print(res_json.get('msg').replace("<br>", "\n"))
            else:
                print(f"âŒ ç¡®è®¤æç°å¤±è´¥: {res_json}")
    except Exception as e:
        print(f"âŒ ç¡®è®¤æç°å“åº”è§£æå¤±è´¥: {e}")


def get_user_info_and_withdraw(domain_url, bbus):
    """
    è·å–ç”¨æˆ·ä¿¡æ¯å¹¶è‡ªåŠ¨æç°
    """
    from urllib.parse import urlparse
    host = urlparse(domain_url).hostname
    withdraw_url = f"http://{host}/haobaobao/withdraw"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/tpg,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "X-Requested-With": "com.tencent.mm",
        "Referer": f"http://{host}/haobaobao/home?v=1751942506",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}"
    }
    try:
        resp = session.get(withdraw_url, headers=headers, timeout=30)
    except requests.exceptions.ReadTimeout as e:
        print(f"[è¶…æ—¶] è·å–ç”¨æˆ·ä¿¡æ¯/æç°é¡µé¢è¶…æ—¶: {e}")
        return None
    except Exception as e:
        print(f"[å¼‚å¸¸] è·å–ç”¨æˆ·ä¿¡æ¯/æç°é¡µé¢å¤±è´¥: {e}")
        return None
    html = resp.text

    # æå–å‚æ•°
    def extract_var(varname):
        m = re.search(rf'var {varname} ?= ?["\']?([^;"\']+)["\']?;', html)
        return m.group(1) if m else None

    request_id = extract_var('request_id')
    nickname = extract_var('nickname')
    qrcode_num = extract_var('qrcode_num')
    isallowtj = extract_var('isallowtj')
    # æå–é‡‘å¸
    m_gold = re.search(r'<p class="f_left" id="exchange_gold">(\d+)</p>', html)
    exchange_gold = int(m_gold.group(1)) if m_gold else 0
    print(f"ç”¨æˆ·ID: {nickname}")
    print(f"é‚€è¯·äººID: {qrcode_num}")
    # print(f"æ˜¯å¦å¯æç°(isallowtj): {isallowtj}")
    print(f"å½“å‰é‡‘å¸: {exchange_gold}")
    # print(f"request_id: {request_id}")
    # è‡ªåŠ¨æç°
    gold = (exchange_gold // 1000) * 1000
    if gold == 0 or not request_id:
        print("âŒ æ— æ³•æç°ï¼Œé‡‘å¸ä¸è¶³æˆ–request_idç¼ºå¤±")
        return request_id
    if gold < MIN_WITHDRAW_GOLD:
        print(f"âŒ å½“å‰é‡‘å¸ {gold} æœªè¾¾åˆ°æç°é—¨æ§› {MIN_WITHDRAW_GOLD}ï¼Œè·³è¿‡æç°")
        return request_id
    post_url = f"http://{host}/haobaobao/getgold"
    post_headers = headers.copy()
    post_headers.update({
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": f"http://{host}",
        "Referer": f"http://{host}/haobaobao/withdraw",
        "Accept": "application/json, text/javascript, */*; q=0.01"
    })
    data = f"request_id={request_id}&gold={gold}"
    print(f"\nğŸ’¸ æ­£åœ¨å‘èµ·æç°ï¼Œé‡‘å¸: {gold}")
    resp2 = session.post(post_url, headers=post_headers, data=data, timeout=15)
    try:
        res_json = resp2.json()
        if res_json.get('errcode') == 0:
            money = res_json.get('data', {}).get('money')
            print(f"âœ… æç°æˆåŠŸï¼Œé‡‘é¢: {money}")
        else:
            if res_json.get('errcode') == 405:
                print(res_json.get('msg').replace("<br>", "\n"))
            else:
                print(f"âŒ æç°å¤±è´¥: {res_json}")
    except Exception as e:
        print(f"âŒ æç°å“åº”è§£æå¤±è´¥: {e}")
    return request_id


def get_promotion_link(domain_url, bbus):
    """
    è·å–æ¨å¹¿é“¾æ¥ï¼Œè¾“å‡ºqrcodes1å’Œä½œè€…æ¨å¹¿é“¾æ¥
    """
    from urllib.parse import urlparse

    host = urlparse(domain_url).hostname
    url = f"http://{host}/tiyvaewmk?v=1"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "User-Agent": UA_USER_AGENT,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "X-Requested-With": "XMLHttpRequest",
        "Referer": f"http://{host}/haobaobao/showcode",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}"
    }
    try:
        resp = session.get(url, headers=headers, timeout=15)
        data = resp.json()
        if data.get('errcode') == 0:
            qrcodes1 = data.get('data', {}).get('qrcodes', {}).get('qrcodes1')
            if qrcodes1:
                # print(f"[ğŸŒŸ æ¨å¹¿é“¾æ¥] {qrcodes1}")
                # è¾“å‡ºä½œè€…æ¨å¹¿é“¾æ¥
                # æ›¿æ¢kstief/åé¢çš„å†…å®¹
                author_link = re.sub(r'(kstief/)[^/?]+(\?tsd=\d+)?', lambda m: m.group(1) + author_code, qrcodes1)
                print(f"[ğŸ‘¨â€ğŸ’» ä½œè€…æ¨å¹¿é“¾æ¥] {author_link}")
            else:
                print("[âŒ æ¨å¹¿é“¾æ¥] æœªæ‰¾åˆ°qrcodes1")
        else:
            print(f"[âŒ æ¨å¹¿é“¾æ¥] è·å–å¤±è´¥: {data}")
    except Exception as e:
        print(f"[âŒ æ¨å¹¿é“¾æ¥] è¯·æ±‚å¼‚å¸¸: {e}")


def refresh_cookie(domain_url, bbus):
    """
    åˆ·æ–°cookieï¼ŒGET /haobaobao/v1{author_code}?v=...ï¼Œå“åº”302ä¸ºæˆåŠŸ
    """
    from urllib.parse import urlparse
    import time
    host = urlparse(domain_url).hostname
    v = int(time.time())
    author_code = "1b69893ab98f0fd50e13e7d3e19d3c65"  # ä¸å…¨å±€å˜é‡ä¿æŒä¸€è‡´
    url = f"http://{host}/haobaobao/v1{author_code}?v={v}"
    headers = {
        "Host": host,
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": UA_USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "X-Requested-With": "com.tencent.mm",
        "Accept-Encoding": "gzip, deflate",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cookie": f"bbus={bbus}"
    }
    try:
        resp = session.get(url, headers=headers, allow_redirects=False, timeout=10)
        if resp.status_code == 302:
            print(f"[Cookieåˆ·æ–°] åˆ·æ–°æˆåŠŸ")
            return True
        else:
            print(f"[Cookieåˆ·æ–°] {host} åˆ·æ–°å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
            return False
    except Exception as e:
        print(f"[Cookieåˆ·æ–°] {host} è¯·æ±‚å¼‚å¸¸: {e}")
        return False


def enter_home(domain_url, bbus):
    """
    è¿›å…¥ä¸»é¡µï¼Œè¿”å›Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    try:
        import time
        from urllib.parse import urlparse
        host = urlparse(domain_url).hostname
        v = int(time.time())
        home_url = f"http://{host}/haobaobao/home?v={v}"
        headers = {
            "Host": host,
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "User-Agent": UA_USER_AGENT,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/wxpic,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "X-Requested-With": "com.tencent.mm",
            "Accept-Encoding": "gzip, deflate",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Cookie": f"bbus={bbus}"
        }
        resp = session.get(home_url, headers=headers, timeout=10)
        if resp.status_code == 200:
            # print(f"[ä¸»é¡µ] è¿›å…¥ä¸»é¡µæˆåŠŸ")
            return True
        else:
            print(f"[Cookieåˆ·æ–°] Cookieåˆ·æ–°å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
            return False
    except Exception as e:
        print(f"[Cookieåˆ·æ–°] Cookieåˆ·æ–°è¯·æ±‚å¼‚å¸¸: {e}")
        return False


# ===== å…¨å±€å˜é‡é…ç½®åŒº =====
MAX_RUNS = 30
author_code = "6c3a4d61c4b9467a869f21007fc8e4fc?tsd=971"
MIN_WITHDRAW_GOLD = 5000  # æ–°å¢ï¼šæç°æ‰€éœ€æœ€å°é‡‘å¸æ•°


if __name__ == "__main__":

    MULTI_ACCOUNT_SPLIT = ["\n", "@", "&"]  # åˆ†éš”ç¬¦åˆ—è¡¨
    BBUS_LIST_OS = os.getenv(f"mmyd_ck")
    if not BBUS_LIST_OS:
        print("âŒ æœªé…ç½®cookieï¼Œç¨‹åºæ— æ³•ç»§ç»­æ‰§è¡Œï¼Œå³å°†é€€å‡º", flush=True)
        exit(1)
    BBUS_LIST = []
    if BBUS_LIST_OS:
        # å¤šåˆ†éš”ç¬¦åˆ†å‰²
        split_pattern = '|'.join(map(re.escape, MULTI_ACCOUNT_SPLIT))
        bbus_items = [x for x in re.split(split_pattern, BBUS_LIST_OS) if x.strip()]
        print(f"ğŸ” ä»ç¯å¢ƒå˜é‡è·å–cookie: {len(bbus_items)} ä¸ª")
        BBUS_LIST.extend(bbus_items)

    print(f"ä»ç¯å¢ƒå˜é‡ä¸­è·å–åˆ°äº†ï¼Œå…±{len(BBUS_LIST)}ä¸ªè´¦å·")
    print(BBUS_LIST)
    # æ£€æŸ¥è‡ªåŠ¨è¿‡æ£€é…ç½®
    if API_URL:
        print(f"âœ… å·²é…ç½®è‡ªåŠ¨è¿‡æ£€æ¥å£: {API_URL}")
    else:
        print("â„¹ï¸ æœªé…ç½®è‡ªåŠ¨è¿‡æ£€æ¥å£ï¼Œæ£€æµ‹æ–‡ç« å°†ç›´æ¥æ¨é€é€šçŸ¥")

    # æ£€æŸ¥æ¨é€tokené…ç½®
    if PUSH_TOKEN:
        print(f"âœ… å·²é…ç½®æ¨é€token: {PUSH_TOKEN}")
    else:
        print("â„¹ï¸ æœªé…ç½®æ¨é€tokenï¼Œæ£€æµ‹æ–‡ç« å°†ä¸ä¼šæ¨é€é€šçŸ¥")

    # æ£€æŸ¥ä»£ç†é…ç½®
    if PROXY_URL:
        print(f"âœ… å·²é…ç½®ä»£ç†: {PROXY_URL}")
    else:
        print("â„¹ï¸ æœªé…ç½®ä»£ç†ï¼Œé‡‡ç”¨æœ¬åœ°è¯·æ±‚")

    # æœ€å¤§è¿è¡Œæ¬¡æ•°ï¼Œé»˜è®¤30æ¬¡
    # MAX_RUNS = 30 # This line is removed as MAX_RUNS is now a global variable
    print(f"æ£€æµ‹åˆ°å…±{len(BBUS_LIST)}ä¸ªè´¦å·")
    for idx, bbus in enumerate(BBUS_LIST):
        proxies = {}
        if PROXY_URL:
            try:
                get_ip = requests.get(PROXY_URL).text
                proxies = {
                    "http": f"http://{get_ip}",
                    "https": f"http://{get_ip}",
                }
                session.proxies = proxies
            except Exception as e:
                print('è·å–ä»£ç†å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç½‘ç»œæ‰§è¡Œ')


        print(f"\n{'=' * 10}ğŸ”°å¼€å§‹æ‰§è¡Œè´¦å·{idx + 1}ğŸ”°{'=' * 10}\n", flush=True)
        try:
            luodi_url = fetch_luodi_url()
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–æ´»åŠ¨åœ°å€å¤±è´¥: {e}")
            continue
        if not luodi_url:
            continue
        try:
            new_host, cid = get_first_redirect(luodi_url)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–è·³è½¬åœ°å€å¤±è´¥: {e}")
            continue
        if not new_host or not cid:
            continue
        # è·å–nLocationåŸŸå
        try:
            location_url, location_domain = get_location_domain(cid, bbus, new_host)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–nLocationåŸŸåå¤±è´¥: {e}")
            continue
        if not location_domain:
            continue
        # ç”¨nLocationåŸŸåæ‹¼æˆdomain_url
        nlocation_domain_url = f"http://{location_domain}"
        # åˆ·æ–°cookie
        try:
            refresh_cookie(nlocation_domain_url, bbus)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] åˆ·æ–°cookieå¤±è´¥: {e}")
            continue
        # åˆ·æ–°åè¿›å…¥ä¸»é¡µ
        try:
            enter_home(nlocation_domain_url, bbus)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è¿›å…¥ä¸»é¡µå¤±è´¥: {e}")
            continue
        # åç»­æµç¨‹ä¾ç„¶ç”¨åŸæœ‰domain_url, sk
        try:
            domain_url, sk = post_mwtmpdomain(location_domain, bbus)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–domain_url/skå¤±è´¥: {e}")
            continue
        # print(f"æœ€ç»ˆç”¨æˆ·url: {domain_url}\nsk: {sk}")
        for run_count in range(1, MAX_RUNS + 1):
            print(f"\nğŸ”„ ç¬¬ {run_count}/{MAX_RUNS} æ¬¡è¿è¡Œ")
            print("-" * 50)
            try:
                success = read_article(domain_url, sk)
            except requests.exceptions.ConnectionError as e:
                print(f"[è¿æ¥é”™è¯¯] é˜…è¯»æ–‡ç« å¤±è´¥: {e}")
                break
            if not success:
                print(f"âŒ ç¬¬ {run_count} æ¬¡è¿è¡Œå¤±è´¥")
                break
            # print(f"âœ… ç¬¬ {run_count} æ¬¡è¿è¡Œå®Œæˆ")
            if run_count < MAX_RUNS:
                wait_time = random.randint(2, 5)
                print(f"â³ ç­‰å¾… {wait_time} ç§’åç»§ç»­ä¸‹ä¸€æ¬¡è¿è¡Œ...")
                time.sleep(wait_time)
        print(f"\nğŸ‰ è´¦å·è¿è¡Œå®Œæˆï¼å…±è¿è¡Œ {run_count} æ¬¡")
        try:
            request_id = get_user_info_and_withdraw(nlocation_domain_url, bbus)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–ç”¨æˆ·ä¿¡æ¯/æç°å¤±è´¥: {e}")
            continue
        # æ–°å¢ï¼šè·å–æ¨å¹¿é“¾æ¥
        try:
            get_promotion_link(nlocation_domain_url, bbus)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] è·å–æ¨å¹¿é“¾æ¥å¤±è´¥: {e}")
            continue
        time.sleep(random.randint(2, 3))
        try:
            confirm_withdraw(nlocation_domain_url, bbus, request_id)
        except requests.exceptions.ConnectionError as e:
            print(f"[è¿æ¥é”™è¯¯] ç¡®è®¤æç°å¤±è´¥: {e}")
            continue
# å½“å‰è„šæœ¬æ¥è‡ªäºhttp://script.345yun.cnè„šæœ¬åº“ä¸‹è½½ï¼